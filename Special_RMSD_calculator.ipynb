{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hoopsforever/AlphaFold-capabilities-with-nanobody-antigen-complex-prediction/blob/main/Special_RMSD_calculator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8A19MFodfvDl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Gy6FLLyvlMp"
      },
      "outputs": [],
      "source": [
        "#@title Install conda\n",
        "%%bash\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-py310_23.3.1-0-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX\n",
        "\n",
        "conda install --channel defaults conda python=3.10 --yes\n",
        "conda update --channel defaults --all --yes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfs6XVVDvpHH"
      },
      "outputs": [],
      "source": [
        "#@title Import libraries\n",
        "import sys\n",
        "_ = (sys.path\n",
        "     .append(\"/usr/local/lib/python3.10/site-packages\"))\n",
        "\n",
        "!conda install -c bioconda anarci\n",
        "import anarci\n",
        "import Bio\n",
        "from Bio.PDB import Superimposer, PDBParser\n",
        "from Bio.PDB.PDBIO import PDBIO\n",
        "from Bio import pairwise2\n",
        "from Bio.pairwise2 import format_alignment\n",
        "import pandas as pd\n",
        "from Bio.SeqUtils import seq1\n",
        "import math\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VPy1vgLv5k5"
      },
      "outputs": [],
      "source": [
        "#@title define functions\n",
        "def clean(pdb_fnm, target_chain):\n",
        "  io = PDBIO()\n",
        "  parser = PDBParser()\n",
        "  structure = parser.get_structure(\"pdb\", pdb_fnm)\n",
        "  #Isolate NB chain\n",
        "  del_chain_ids = []\n",
        "  for model in structure:\n",
        "    for chain in model:\n",
        "      if chain.id != target_chain:\n",
        "        del_chain_ids.append(chain.id)\n",
        "\n",
        "    for id in del_chain_ids:\n",
        "      model.detach_child(id)\n",
        "\n",
        "  #Get rid of hydrogen atoms\n",
        "  del_hydro = []\n",
        "  for model in structure:\n",
        "      for chain in model:\n",
        "        for residue in chain.get_residues():\n",
        "          for atom in residue.get_atoms():\n",
        "            if atom.element == \"H\":\n",
        "              del_hydro.append([chain.id, residue.id, atom.id])\n",
        "\n",
        "  for H in del_hydro:\n",
        "    model[H[0]][H[1]].detach_child(H[2])\n",
        "\n",
        "  #Get rid of OTX atoms\n",
        "  del_OXT = []\n",
        "  for model in structure:\n",
        "      for chain in model:\n",
        "        for residue in chain.get_residues():\n",
        "          for atom in residue.get_atoms():\n",
        "            if atom.element == \"OXT\":\n",
        "              del_OXT.append([chain.id, residue.id, atom.id])\n",
        "\n",
        "  for T in del_OXT:\n",
        "    model[T[0]][T[1]].detach_child(T[2])\n",
        "\n",
        "  #Get rid of heteroatoms\n",
        "  del_het = []\n",
        "  for model in structure:\n",
        "    for chain in model:\n",
        "      for residue in chain.get_residues():\n",
        "        if residue.get_id()[0] != \" \":\n",
        "          del_het.append(residue.get_id())\n",
        "\n",
        "    for hetero in del_het:\n",
        "        chain.detach_child(hetero)\n",
        "\n",
        "  io.set_structure(structure)\n",
        "  return structure\n",
        "\n",
        "def normalize(pdb1_fnm, chain_1, pdb2_fnm, chain_2, out_dir):\n",
        "  io = PDBIO()\n",
        "  parser = PDBParser()\n",
        "  structure1 = parser.get_structure(\"pdb1\", pdb1_fnm)\n",
        "  structure2 = parser.get_structure(\"pdb2\", pdb2_fnm)\n",
        "\n",
        "  pdb1 = pdb1_fnm[-10:-6]\n",
        "  pdb2 = pdb2_fnm[-10:-6]\n",
        "\n",
        "  alignments = pairwise2.align.globalms(nanobody_sequences(pdb1_fnm, chain_1),nanobody_sequences2(pdb2_fnm, chain_2), 2, -1, -.5, -.1) # find alignments\n",
        "\n",
        "  aligned_sequence1 = alignments[0][0]\n",
        "  aligned_sequence2 = alignments[0][1]\n",
        "\n",
        "  # Find positions where the sequences differ\n",
        "  differences = [i for i, (a, b) in enumerate(zip(aligned_sequence1, aligned_sequence2)) if a != b]\n",
        "  # go through the entire 'differences' list; for all the positions with a dash in a particular sequence, that index will correspond\n",
        "  # to a number in the 'differences' list; delete the residue ids from that sequence that correspond to the 'differences' number\n",
        "\n",
        "  del_count1 = []\n",
        "  del_count2 = []\n",
        "  for items in differences:\n",
        "    if aligned_sequence2[items] == \"-\":\n",
        "      del_count1.append(items)\n",
        "    elif aligned_sequence1[items] == \"-\":\n",
        "      del_count2.append(items)\n",
        "\n",
        "  del_res1 = []\n",
        "  counter = 0\n",
        "  for model in structure1:\n",
        "    for chain in model:\n",
        "      for residue in chain:\n",
        "        while  counter<len(aligned_sequence1) and aligned_sequence1[counter] == '-':\n",
        "            counter += 1\n",
        "        if counter in del_count1:\n",
        "          del_res1.append(residue.get_id())\n",
        "        counter += 1\n",
        "\n",
        "  for res in del_res1:\n",
        "    structure1[0][nb1].detach_child(res)\n",
        "\n",
        "  del_res2 = []\n",
        "  counter = 0\n",
        "  for model in structure2:\n",
        "      for chain in model:\n",
        "          for residue in chain:\n",
        "            while counter<len(aligned_sequence2) and aligned_sequence2[counter] == '-':\n",
        "              counter += 1\n",
        "            if counter in del_count2:\n",
        "              del_res2.append(residue.get_id())\n",
        "            counter += 1\n",
        "\n",
        "  for res in del_res2:\n",
        "    structure2[0][nb2].detach_child(res)\n",
        "\n",
        "  io.set_structure(structure1)\n",
        "  io.save(out_dir + f'/{pdb1}_{chain_1}_nomr.pdb', preserve_atom_numbering = True)\n",
        "\n",
        "  io.set_structure(structure2)\n",
        "  io.save(out_dir + f'/{pdb2}_{chain_2}_nomr.pdb', preserve_atom_numbering = True)\n",
        "\n",
        "def normalize_struct(struct1, pdb1, chain1, struct2, pdb2, chain2, out_dir1, out_dir2):\n",
        "  io = PDBIO()\n",
        "  alignments = pairwise2.align.globalms(struct_seq(struct1, chain1), struct_seq(struct2, chain2), 2, -1, -.5, -.1) # find alignments\n",
        "\n",
        "  aligned_sequence1 = alignments[0][0]\n",
        "  aligned_sequence2 = alignments[0][1]\n",
        "\n",
        "  # Find positions where the sequences differ\n",
        "  differences = [i for i, (a, b) in enumerate(zip(aligned_sequence1, aligned_sequence2)) if a != b]\n",
        "  # go through the entire 'differences' list; for all the positions with a dash in a particular sequence, that index will correspond\n",
        "  # to a number in the 'differences' list; delete the residue ids from that sequence that correspond to the 'differences' number\n",
        "\n",
        "  del_count1 = []\n",
        "  del_count2 = []\n",
        "  for items in differences:\n",
        "    if aligned_sequence2[items] == \"-\":\n",
        "      del_count1.append(items)\n",
        "    elif aligned_sequence1[items] == \"-\":\n",
        "      del_count2.append(items)\n",
        "\n",
        "  del_res1 = []\n",
        "  counter = 0\n",
        "  for model in struct1:\n",
        "    for chain in model:\n",
        "      for residue in chain:\n",
        "        while  counter<len(aligned_sequence1) and aligned_sequence1[counter] == '-':\n",
        "            counter += 1\n",
        "        if counter in del_count1:\n",
        "          del_res1.append(residue.get_id())\n",
        "        counter += 1\n",
        "\n",
        "  for res in del_res1:\n",
        "    struct1[0][chain1].detach_child(res)\n",
        "\n",
        "  del_res2 = []\n",
        "  counter = 0\n",
        "  for model in struct2:\n",
        "      for chain in model:\n",
        "          for residue in chain:\n",
        "            while counter<len(aligned_sequence2) and aligned_sequence2[counter] == '-':\n",
        "              counter += 1\n",
        "            if counter in del_count2:\n",
        "              del_res2.append(residue.get_id())\n",
        "            counter += 1\n",
        "\n",
        "  for res in del_res2:\n",
        "    struct2[0][chain2].detach_child(res)\n",
        "\n",
        "  #renumber PDBs from 1\n",
        "  for model in struct1:\n",
        "        for chain in model:\n",
        "            counter = 1\n",
        "            for residue in chain:\n",
        "                if 'resseq=' + str(counter) + ' icode= ' in str(list(chain.get_residues())):\n",
        "                    chain[counter].id = (' ', counter + 1000, ' ')\n",
        "                    residue.id = (' ', counter, ' ')\n",
        "                    counter += 1\n",
        "                else:\n",
        "                    residue.id = (' ', counter, ' ')\n",
        "                    counter += 1\n",
        "\n",
        "  for model in struct2:\n",
        "        for chain in model:\n",
        "            counter = 1\n",
        "            for residue in chain:\n",
        "                if 'resseq=' + str(counter) + ' icode= ' in str(list(chain.get_residues())):\n",
        "                    chain[counter].id = (' ', counter + 1000, ' ')\n",
        "                    residue.id = (' ', counter, ' ')\n",
        "                    counter += 1\n",
        "                else:\n",
        "                    residue.id = (' ', counter, ' ')\n",
        "                    counter += 1\n",
        "\n",
        "  #save normalized PDBs\n",
        "  io.set_structure(struct1)\n",
        "  io.save(out_dir1 + f'/{pdb1}_{chain1}_nomr.pdb', preserve_atom_numbering = True)\n",
        "\n",
        "  io.set_structure(struct2)\n",
        "  io.save(out_dir2 + f'/{pdb2}_{chain2}_nomr.pdb', preserve_atom_numbering = True)\n",
        "\n",
        "def nanobody_sequence(pdb_fnm, nb_chain):\n",
        "  parser = PDBParser()\n",
        "  structure = parser.get_structure(\"pdb\", pdb_fnm)\n",
        "  AA_seq = '' #holds the string of one letter amino acid codes for the nanobody from the prediction file\n",
        "  chains = ''\n",
        "  for model in structure.get_models():\n",
        "    for chain in model.get_chains():\n",
        "      if chain.get_id() == nb_chain:\n",
        "        for residue in chain.get_residues(): # access residues\n",
        "            residue_name = seq1(residue.get_resname())\n",
        "            if residue_name == \"X\":\n",
        "              continue\n",
        "            AA_seq+=residue_name\n",
        "  return AA_seq\n",
        "\n",
        "def struct_seq(struct, nb_chain):\n",
        "  AA_seq = ''\n",
        "  chains = ''\n",
        "  for model in struct.get_models():\n",
        "    for chain in model.get_chains():\n",
        "      if chain.get_id() == nb_chain:\n",
        "        for residue in chain.get_residues(): # access residues\n",
        "            residue_name = seq1(residue.get_resname())\n",
        "            if residue_name == \"X\":\n",
        "              continue\n",
        "            AA_seq+=residue_name\n",
        "  return AA_seq\n",
        "\n",
        "def anarci_df(sequence):\n",
        "  query = anarci.run_anarci(sequence)[1][0][0]\n",
        "  start = query[1]\n",
        "  data = query[0]\n",
        "\n",
        "  imgt = []\n",
        "  for i in range(0, len(data)):\n",
        "    new = {}\n",
        "    new['res'] = data[i][-1]\n",
        "    new['num'] = (str(data[i][0][0]) + data[i][0][1]).replace(' ', '')\n",
        "    imgt.append(new)\n",
        "  DF = pd.DataFrame(imgt)\n",
        "  DF = DF[DF['res'] != '-']\n",
        "  DF = DF.reset_index(drop = True)\n",
        "  return DF, start\n",
        "\n",
        "def superimpose(pdb_file1, pdb_file2):\n",
        "  # Create a PDB parser\n",
        "  parser = PDBParser()\n",
        "\n",
        "  # Get the structures\n",
        "  structure1 = parser.get_structure(\"Protein 1\", pdb_file1)\n",
        "  structure2 = parser.get_structure(\"Protein 2\", pdb_file2)\n",
        "\n",
        "  # Get the first model in the structures\n",
        "  model1 = structure1[0]\n",
        "  model2 = structure2[0]\n",
        "\n",
        "  # Choose the first chain in the model\n",
        "  chain1 = model1.get_list()[0]\n",
        "  chain2 = model2.get_list()[0]\n",
        "\n",
        "  # Get the list of atoms for the full chains\n",
        "  full_atoms1 = [atom for atom in chain1.get_atoms()]\n",
        "  full_atoms2 = [atom for atom in chain2.get_atoms()]\n",
        "\n",
        "\n",
        "  # Superimpose structure2 on structure1\n",
        "  super_imposer = Superimposer()\n",
        "  super_imposer.set_atoms(full_atoms1, full_atoms2)\n",
        "  super_imposer.apply(chain2.get_atoms())\n",
        "\n",
        "  #set new structure for superimposed structure 2\n",
        "  io = Bio.PDB.PDBIO()\n",
        "  io.set_structure(structure2)\n",
        "\n",
        "  return structure2\n",
        "\n",
        "def superimpose_backbone(pdb_file1, pdb_file2):\n",
        "  # Create a PDB parser\n",
        "  parser = PDBParser()\n",
        "\n",
        "  # Get the structures\n",
        "  structure1 = parser.get_structure(\"Protein 1\", pdb_file1)\n",
        "  structure2 = parser.get_structure(\"Protein 2\", pdb_file2)\n",
        "\n",
        "  # Get the first model in the structures\n",
        "  model1 = structure1[0]\n",
        "  model2 = structure2[0]\n",
        "\n",
        "  # Choose the first chain in the model\n",
        "  chain1 = model1.get_list()[0]\n",
        "  chain2 = model2.get_list()[0]\n",
        "\n",
        "  # Get lists of all C N O CA atoms\n",
        "  full_atoms1 = [atom for atom in chain1.get_atoms() if atom.id in ['C', 'N', 'O', 'CA']]\n",
        "  full_atoms2 = [atom for atom in chain2.get_atoms() if atom.id in ['C', 'N', 'O', 'CA']]\n",
        "\n",
        "\n",
        "  # Superimpose structure2 on structure1\n",
        "  super_imposer = Superimposer()\n",
        "  super_imposer.set_atoms(full_atoms1, full_atoms2)\n",
        "  super_imposer.apply(full_atoms2)\n",
        "\n",
        "  #set new structure for superimposed structure 2\n",
        "  io = Bio.PDB.PDBIO()\n",
        "  io.set_structure(structure2)\n",
        "\n",
        "  return structure2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary1 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Rishi_project_files/Compare_Conformations/Reference_chart.txt\",header=None)\n",
        "summary2 = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Rishi_project_files/Compare_Conformations/Reference_chart_prediction_w_model.txt\",header = None)\n",
        "\n",
        "dir1 = sorted(os.listdir('/content/drive/MyDrive/Colab Notebooks/Rishi_project_files/Compare_Contacts/Final/without_target'))\n",
        "dir2 = sorted(os.listdir('/content/drive/MyDrive/Colab Notebooks/Rishi_project_files/Compare_Contacts/Final/with_target'))\n",
        "\n",
        "pdb1_fnm = f'/content/drive/MyDrive/Colab Notebooks/Rishi_project_files/Compare_Contacts/Final/without_target/{dir1[2]}'\n",
        "pdb2_fnm = f'/content/drive/MyDrive/Colab Notebooks/Rishi_project_files/Compare_Contacts/Final/with_target/{dir2[2]}'\n",
        "\n",
        "nb_notar = dir1[2][5]\n",
        "nb_orig = dir2[2][5]\n",
        "\n",
        "seq_AA = nanobody_sequence(pdb1_fnm, nb_notar)\n",
        "imgt, start = anarci_df(seq_AA)\n",
        "\n",
        "parser = PDBParser()\n",
        "structure1 = parser.get_structure('Protein 1', pdb1_fnm)\n",
        "structure2 = superimpose(pdb1_fnm, pdb2_fnm)\n",
        "\n",
        "model1 = structure1[0]\n",
        "model2 = structure2[0]\n",
        "\n",
        "chain1 = model1.get_list()[0]\n",
        "chain2 = model2.get_list()[0]"
      ],
      "metadata": {
        "id": "-A4zlNgYNV4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(chain1.get_atoms())"
      ],
      "metadata": {
        "id": "jrWiNQX3ueVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title normalize pdbs\n",
        "dir1 = '/content/drive/MyDrive/Colab Notebooks/Rishi_project_files/Compare_Conformations/models_target'\n",
        "dir2 = '/content/drive/MyDrive/Colab Notebooks/Rishi_project_files/Compare_Conformations/models_notarget'\n",
        "out_dir1 = '/content/drive/MyDrive/Colab Notebooks/Rishi_project_files/Compare_Conformations/normalized_pdbs/Normalized_target' # file where you want to save to\n",
        "out_dir2 = '/content/drive/MyDrive/Colab Notebooks/Rishi_project_files/Compare_Conformations/normalized_pdbs/Normalized_notarget'\n",
        "\n",
        "files1 = sorted(os.listdir(dir1))\n",
        "files2 = sorted(os.listdir(dir2))\n",
        "\n",
        "for i in range(0, len(files1)):\n",
        "  pdb1 = files1[i][0:4]\n",
        "  pdb2 = files2[i][0:4]\n",
        "  chain1 = files1[i][5]\n",
        "  chain2 = files2[i][5]\n",
        "\n",
        "  clean1 = clean(dir1+ '/' + files1[i], chain1)\n",
        "  clean2 = clean(dir2 + '/' + files2[i], chain2)\n",
        "\n",
        "  normalize_struct(clean1, pdb1, chain1, clean2, pdb2, chain2, out_dir1, out_dir2)"
      ],
      "metadata": {
        "id": "J-euVvCY8U5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str(list(chain.get_residues()))"
      ],
      "metadata": {
        "id": "jXN0WjM75y3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdb1_fnm = dir1 + f'/{files1[2]}'\n",
        "pdb2_fnm = dir2 + f'/{files2[2]}'\n",
        "chain1 = files1[2][5]\n",
        "chain2 = files2[2][5]\n",
        "\n",
        "#nb_notar = summary1.iloc[i,0][5]\n",
        "#nb_orig = summary2.iloc[i,0][5]\n",
        "\n",
        "seq_AA = nanobody_sequence(pdb1_fnm, chain1)\n",
        "imgt, start = anarci_df(seq_AA)\n",
        "\n",
        "parser = PDBParser()\n",
        "structure1 = parser.get_structure('Protein 1', pdb1_fnm)\n",
        "structure2 = superimpose_backbone(pdb1_fnm, pdb2_fnm)\n",
        "\n",
        "model1 = structure1[0]\n",
        "model2 = structure2[0]\n",
        "\n",
        "chain1 = model1.get_list()[0]\n",
        "chain2 = model2.get_list()[0]\n",
        "\n",
        "#start += chain1.get_list()[0].get_id()[1] - 1\n",
        "\n",
        "#loop indexes\n",
        "CDR1_start = imgt['num'][imgt['num'] == '27'].index[0]+start\n",
        "CDR1_end = imgt['num'][imgt['num'] == '39'].index[0]+start\n",
        "\n",
        "CDR2_start = imgt['num'][imgt['num'] == '56'].index[0]+start\n",
        "CDR2_end = imgt['num'][imgt['num'] == '67'].index[0]+start\n",
        "\n",
        "CDR3_start = imgt['num'][imgt['num'] == '105'].index[0]+start\n",
        "CDR3_end = imgt['num'][imgt['num'] == '117'].index[0]+start"
      ],
      "metadata": {
        "id": "R6V9vbHBjHo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rz4eBoVhdnv2"
      },
      "outputs": [],
      "source": [
        "#@title run rmsd\n",
        "#summary1 = pd.read_csv(\"/content/drive/MyDrive/Rishi_project_files/Compare_Conformations/Reference_chart.txt\",header=None)\n",
        "#summary2 = pd.read_csv(\"/content/drive/MyDrive/Rishi_project_files/Compare_Conformations/Reference_chart_prediction_w_model.txt\",header = None)\n",
        "\n",
        "dir1 = '/content/drive/MyDrive/Colab Notebooks/Rishi_project_files/Compare_Conformations/control_nbs/normalized_with_target'\n",
        "dir2 = '/content/drive/MyDrive/Colab Notebooks/Rishi_project_files/Compare_Conformations/control_nbs/normalized_without_target'\n",
        "files1 = sorted(os.listdir('/content/drive/MyDrive/Colab Notebooks/Rishi_project_files/Compare_Conformations/control_nbs/normalized_with_target'))\n",
        "files2 = sorted(os.listdir('/content/drive/MyDrive/Colab Notebooks/Rishi_project_files/Compare_Conformations/control_nbs/normalized_without_target'))\n",
        "\n",
        "RMSDs = []\n",
        "for i in range(0, len(files1)):\n",
        "\n",
        "  pdb1_fnm = dir1 + f'/{files1[i]}'\n",
        "  pdb2_fnm = dir2 + f'/{files2[i]}'\n",
        "  chain1 = files1[i][5]\n",
        "  chain2 = files2[i][5]\n",
        "\n",
        "  #nb_notar = summary1.iloc[i,0][5]\n",
        "  #nb_orig = summary2.iloc[i,0][5]\n",
        "\n",
        "  seq_AA = nanobody_sequence(pdb1_fnm, chain1)\n",
        "  imgt, start = anarci_df(seq_AA)\n",
        "\n",
        "  parser = PDBParser()\n",
        "  structure1 = parser.get_structure('Protein 1', pdb1_fnm)\n",
        "  structure2 = superimpose_backbone(pdb1_fnm, pdb2_fnm)\n",
        "\n",
        "  model1 = structure1[0]\n",
        "  model2 = structure2[0]\n",
        "\n",
        "  chain1 = model1.get_list()[0]\n",
        "  chain2 = model2.get_list()[0]\n",
        "\n",
        "  #start += chain1.get_list()[0].get_id()[1] - 1\n",
        "\n",
        "  #loop indexes\n",
        "  CDR1_start = imgt['num'][imgt['num'] == '27'].index[0]+start\n",
        "  CDR1_end = imgt['num'][imgt['num'] == '39'].index[0]+start\n",
        "\n",
        "  CDR2_start = imgt['num'][imgt['num'] == '56'].index[0]+start\n",
        "  CDR2_end = imgt['num'][imgt['num'] == '67'].index[0]+start\n",
        "\n",
        "  CDR3_start = imgt['num'][imgt['num'] == '105'].index[0]+start\n",
        "  CDR3_end = imgt['num'][imgt['num'] == '117'].index[0]+start\n",
        "\n",
        "  s1_fr1_atoms = [atom for atom in chain1.get_atoms() if start <= atom.get_parent().get_id()[1] < CDR1_start and atom.id in ['C', 'N', 'O', 'CA']]\n",
        "  s1_cdr1_atoms = [atom for atom in chain1.get_atoms() if CDR1_start <= atom.get_parent().get_id()[1] < CDR1_end and atom.id in ['C', 'N', 'O', 'CA']]\n",
        "  s1_fr2_atoms = [atom for atom in chain1.get_atoms() if CDR1_end <= atom.get_parent().get_id()[1] < CDR2_start and atom.id in ['C', 'N', 'O', 'CA']]\n",
        "  s1_cdr2_atoms = [atom for atom in chain1.get_atoms() if CDR2_start <= atom.get_parent().get_id()[1] < CDR2_end and atom.id in ['C', 'N', 'O', 'CA']]\n",
        "  s1_fr3_atoms = [atom for atom in chain1.get_atoms() if CDR2_end <= atom.get_parent().get_id()[1] < CDR3_start and atom.id in ['C', 'N', 'O', 'CA']]\n",
        "  s1_cdr3_atoms = [atom for atom in chain1.get_atoms() if CDR3_start <= atom.get_parent().get_id()[1] < CDR3_end and atom.id in ['C', 'N', 'O', 'CA']]\n",
        "  s1_fr4_atoms = [atom for atom in chain1.get_atoms() if CDR3_end <= atom.get_parent().get_id()[1] < len(imgt)+start and atom.id in ['C', 'N', 'O', 'CA']]\n",
        "\n",
        "  s2_fr1_atoms = [atom for atom in chain2.get_atoms() if start <= atom.get_parent().get_id()[1] < CDR1_start and atom.id in ['C', 'N', 'O', 'CA']]\n",
        "  s2_cdr1_atoms = [atom for atom in chain2.get_atoms() if CDR1_start <= atom.get_parent().get_id()[1] < CDR1_end and atom.id in ['C', 'N', 'O', 'CA']]\n",
        "  s2_fr2_atoms = [atom for atom in chain2.get_atoms() if CDR1_end <= atom.get_parent().get_id()[1] < CDR2_start and atom.id in ['C', 'N', 'O', 'CA']]\n",
        "  s2_cdr2_atoms = [atom for atom in chain2.get_atoms() if CDR2_start <= atom.get_parent().get_id()[1] < CDR2_end and atom.id in ['C', 'N', 'O', 'CA']]\n",
        "  s2_fr3_atoms = [atom for atom in chain2.get_atoms() if CDR2_end <= atom.get_parent().get_id()[1] < CDR3_start and atom.id in ['C', 'N', 'O', 'CA']]\n",
        "  s2_cdr3_atoms = [atom for atom in chain2.get_atoms() if CDR3_start <= atom.get_parent().get_id()[1] < CDR3_end and atom.id in ['C', 'N', 'O', 'CA']]\n",
        "  s2_fr4_atoms = [atom for atom in chain2.get_atoms() if CDR3_end <= atom.get_parent().get_id()[1] < len(imgt)+start and atom.id in ['C', 'N', 'O', 'CA']]\n",
        "\n",
        "  len_fr1 = len(s1_fr1_atoms)\n",
        "  len_cdr1 = len(s1_cdr1_atoms)\n",
        "  len_fr2 = len(s1_fr2_atoms)\n",
        "  len_cdr2 = len(s1_cdr2_atoms)\n",
        "  len_fr3 = len(s1_fr3_atoms)\n",
        "  len_cdr3 = len(s1_cdr3_atoms)\n",
        "  len_fr4 = len(s1_fr4_atoms)\n",
        "  len_frs = len_fr1 + len_fr2 + len_fr3 + len_fr4\n",
        "  len_cdrs = len_cdr1 + len_cdr2 + len_cdr3\n",
        "  len_tot = len_frs + len_cdrs\n",
        "\n",
        "  sum = 0\n",
        "  for j in range(0,len_fr1):\n",
        "    sum += (math.dist(s1_fr1_atoms[j].get_coord(), s2_fr1_atoms[j].get_coord()))**2\n",
        "  rmsd_fr1 = math.sqrt(sum/len_fr1)\n",
        "\n",
        "  sum = 0\n",
        "  for j in range(0,len_cdr1):\n",
        "    sum += (math.dist(s1_cdr1_atoms[j].get_coord(), s2_cdr1_atoms[j].get_coord()))**2\n",
        "  rmsd_cdr1 = math.sqrt(sum/len_cdr1)\n",
        "\n",
        "  sum = 0\n",
        "  for j in range(0,len_fr2):\n",
        "    sum += (math.dist(s1_fr2_atoms[j].get_coord(), s2_fr2_atoms[j].get_coord()))**2\n",
        "  rmsd_fr2 = math.sqrt(sum/len_fr2)\n",
        "\n",
        "  sum = 0\n",
        "  for j in range(0,len_cdr2):\n",
        "    sum += (math.dist(s1_cdr2_atoms[j].get_coord(), s2_cdr2_atoms[j].get_coord()))**2\n",
        "  rmsd_cdr2 = math.sqrt(sum/len_cdr2)\n",
        "\n",
        "  sum = 0\n",
        "  for j in range(0,len_fr3):\n",
        "    sum += (math.dist(s1_fr3_atoms[j].get_coord(), s2_fr3_atoms[j].get_coord()))**2\n",
        "  rmsd_fr3 = math.sqrt(sum/len_fr3)\n",
        "\n",
        "  sum = 0\n",
        "  for j in range(0,len_cdr3):\n",
        "    sum += (math.dist(s1_cdr3_atoms[j].get_coord(), s2_cdr3_atoms[j].get_coord()))**2\n",
        "  rmsd_cdr3 = math.sqrt(sum/len_cdr3)\n",
        "\n",
        "  sum = 0\n",
        "  for j in range(0,len_fr4):\n",
        "    sum += (math.dist(s1_fr4_atoms[j].get_coord(), s2_fr4_atoms[j].get_coord()))**2\n",
        "  rmsd_fr4 = math.sqrt(sum/len_fr4)\n",
        "\n",
        "  fr_avg = math.sqrt((((rmsd_fr1**2)*len_fr1) + ((rmsd_fr2**2)*len_fr2) + ((rmsd_fr3**2)*len_fr3) + ((rmsd_fr4**2)*len_fr4))/len_frs)\n",
        "  cdr_avg = math.sqrt((((rmsd_cdr1**2)*len_cdr1) + ((rmsd_cdr2**2)*len_cdr2) + ((rmsd_cdr3**2)*len_cdr3))/len_cdrs)\n",
        "  tot_avg = math.sqrt((((rmsd_fr1**2)*len_fr1) + ((rmsd_fr2**2)*len_fr2) + ((rmsd_fr3**2)*len_fr3) + ((rmsd_fr4**2)*len_fr4) + ((rmsd_cdr1**2)*len_cdr1) + ((rmsd_cdr2**2)*len_cdr2) + ((rmsd_cdr3**2)*len_cdr3))/len_tot)\n",
        "\n",
        "  #RMSDs.append([dir1[i], f'FR1:{rmsd_fr1:.3f}', f'CDR1:{rmsd_cdr1:.3f}', f'FR2:{rmsd_fr2:.3f}', f'CDR2:{rmsd_cdr2:.3f}', f'FR3:{rmsd_fr3:.3f}', f'CDR3:{rmsd_cdr3:.3f}', f'FR4:{rmsd_fr4:.3f}', f'FR_avg:{fr_avg:.3f}', f'CDR_avg:{cdr_avg:.3f}', f'TOT_RMSD:{tot_avg:.3f}'])\n",
        "  RMSDs.append([files1[i], f'FR1:{rmsd_fr1:.3f}', f'CDR1:{rmsd_cdr1:.3f}', f'FR2:{rmsd_fr2:.3f}', f'CDR2:{rmsd_cdr2:.3f}', f'FR3:{rmsd_fr3:.3f}', f'CDR3:{rmsd_cdr3:.3f}', f'FR4:{rmsd_fr4:.3f}', f'FR_avg:{fr_avg:.3f}', f'CDR_avg:{cdr_avg:.3f}', f'TOT_RMSD:{tot_avg:.3f}'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RMSDs"
      ],
      "metadata": {
        "id": "YyTK3f2MjX8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title test individual full rmsd values\n",
        "pdb1_fnm = f'/content/drive/MyDrive/Rishi_project_files/Compare_Conformations/normalized_pdbs/Normalized_notarget/{dir1[0]}'\n",
        "pdb2_fnm = f'/content/drive/MyDrive/Rishi_project_files/Compare_Conformations/normalized_pdbs/Normalized_target/{dir2[0]}'\n",
        "\n",
        "parser = PDBParser()\n",
        "\n",
        "# Get the structures\n",
        "structure1 = parser.get_structure(\"Protein 1\", pdb1_fnm)\n",
        "structure2 = parser.get_structure(\"Protein 2\", pdb2_fnm)\n",
        "\n",
        "# Get the first model in the structures\n",
        "model1 = structure1[0]\n",
        "model2 = structure2[0]\n",
        "\n",
        "# Choose the first chain in the model\n",
        "chain1 = model1.get_list()[0]\n",
        "chain2 = model2.get_list()[0]\n",
        "\n",
        "# Get the list of atoms for the full chains\n",
        "full_atoms1 = [atom for atom in chain1.get_atoms()]\n",
        "full_atoms2 = [atom for atom in chain2.get_atoms()]\n",
        "\n",
        "# Get the list of atoms for the specific region\n",
        "\n",
        "\n",
        "# Superimpose structure2 on structure1\n",
        "super_imposer = Superimposer()\n",
        "super_imposer.set_atoms(full_atoms1, full_atoms2)\n",
        "super_imposer.apply(chain2.get_atoms())\n",
        "\n",
        "super_imposer.rms"
      ],
      "metadata": {
        "id": "Ydb5vkaqeish"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}